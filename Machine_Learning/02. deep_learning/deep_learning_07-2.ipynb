{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "심층 신경망\n",
    "- 인공 신경망에 층을 여러개 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 픽섹 범위로 나누고 스케일하기\n",
    "train_scaled = train_input / 255.0\n",
    "train_scaled = train_scaled.reshape(-1, 28*28)\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공 신경망 모델에 층을 2개 추가\n",
    "# 입력층과 출력층 사이에 밀집층 추가\n",
    "\n",
    "# 은닉층(hidden layer) : 입력층과 출력층 사이에 있는 모든 함수 \n",
    "\n",
    "# 회귀를 위한 신경망의 출력층에는 어떤 활성화 함수 사용?\n",
    "# >> 회귀는 임이의 어떤 수 이므로 활성화 함수 적용x \n",
    "# Dense의 activation 매개변수에 아무런 값도 지정x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
    "dense2 = keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "# dense1 은닉층 10개의 뉴런을 가진 밀집층\n",
    "# 은닉층의 뉴런 개수를 정하는 데는 특별한 기준은 없고 , 몇 개의 뉴런을 두어야 할지 판단하기 위해서 상당하 경험 필요로 함.\n",
    "# 제약사항 : 적어도 출력층의 뉴런보다는 많아야 함.\n",
    "# dense2 출력층> 10개 클래스를 분류하므로 10개 뉴런  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 심층 신경망 만들기(deep neural newtwork, DNN)\n",
    "model = keras.Sequential([dense1, dense2])\n",
    "\n",
    "# Sequential클래스의 객체를 만들 때 여러 개의 층을 추가하려면 dense1과 dense2를 리스트로 만들어 전달.\n",
    "# 주의 : 출력층을 가장 마지막에 두어야 함.\n",
    "# 가장 처음 등장하는 은늑층에서 마지막 출력층 순으로 나열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary() 메서드 호출 >> 층에 대한 유용한 정보 얻을 수 있음\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "층을 추가하는 다른 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞에서는 Dense 클래스 객체 dense1, dense2를 만들어 Squential 클래스에 전달했는데 \n",
    "# 이 두 객체를 따로 저장해 쓸일이 없어 \n",
    "# Sequential 클래스와 생성자 안에서 바로  Dense 클래스의 객체를 만드는 경우가 많음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name = 'hidden'),\n",
    "    keras.layers.Dense(10, activation='softmax', name = 'output')\n",
    "], name= '패션 MNIST 모델')\n",
    "\n",
    "# 추가되는 층을 한 눈에 볼 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"패션 MNIST 모델\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add() 메서드 사용하여 Sequential 클래스 층 추가하기\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.5733 - accuracy: 0.8064\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.4142 - accuracy: 0.8520\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3784 - accuracy: 0.8640\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3556 - accuracy: 0.8717\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3373 - accuracy: 0.8776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x232c26cd520>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_scaled, train_target, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능이 향상됨을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "렐루 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초창기엔 인공 신경망의 은닉층에 시그모이드 함수를 많이 사용했는데\n",
    "# 시그모이드 함수는 오른쪽과 왼쪽 끝으로갈 수록 그래프가 누워있어 올바른 출력을 만드는데 \n",
    "# 신속하게 대응하지 못함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특히 층이 많은 심층 신경망일수록 그 효과가 누적되어 학습을 더 어렵게 함.\n",
    "# 개선을 위해 제안된 함수가 렐루(relu) 함수.\n",
    "\n",
    "# 렐루 함수 : 입력이 양수일 경우 마치 활성화 함수가 없는 것처럼 그냥 입력 통과\n",
    "        # :음수일 경우 0으로 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 렐루 함수 : max(0,z)와 같이 쓸 수 있음.\n",
    "# 렐루함수는 특히 이미지 처리에서 좋은 성능을 냄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패녓 MNIST 데이터는28*28 크기이기 때문에 인공 신경망에 주입하기 위해 넘파이 배열의\n",
    "# reshape() 메서드를 사용해 1차원으로 펼쳤음\n",
    "\n",
    "# >> keras에 Flatten 층을 제공함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten함수 : 배치 차원을 제외하고 나머지 입력 차원을 모두 일렬로 펼치는 역할\n",
    "# 입력에 곱해지는 가중치나 절편 없음.\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "train_scaled = train_input /225.0\n",
    "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3059 - accuracy: 0.8917\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2932 - accuracy: 0.8959\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2876 - accuracy: 0.8992\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2791 - accuracy: 0.9016\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2707 - accuracy: 0.9046\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2655 - accuracy: 0.9075\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2623 - accuracy: 0.9075\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2579 - accuracy: 0.9110\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2514 - accuracy: 0.9120\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2484 - accuracy: 0.9150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x232824c54f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
    "model.fit(train_scaled, train_target, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 1ms/step - loss: 0.4117 - accuracy: 0.8826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4117205739021301, 0.8825833201408386]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_scaled, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제까지 다룬 하이퍼 파라미터 \n",
    "# : 은늑층의 개수, 뉴런 개수, 활성화 함수, 층의 종류, 배치 사이즈 매개변수, 에포크 매개변수 등\n",
    "\n",
    "# keras는 기본적으로 미니배치 경사 하강법을 사용하여 미니배치 개수 32\n",
    "# fit() 메서드의 batch_size 매개변수에서 조정 가능 > 하이퍼파라미터\n",
    "# epochs 매개변수도 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "옵티마이저(optimizer) : keras에서 제공하는 다양한 종류의 경사 하강법 알고리즘.\n",
    "compile() 메서드에서 카라스의 기본 경사 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
